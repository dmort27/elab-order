{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from libraries.lahu_jam.lahu_jam_regex import LAHU_REGEX as lahu\n",
    "import epitran, panphon\n",
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/lahu/elabs_from_ell/elabs_extracted.csv\", quoting=csv.QUOTE_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>word3</th>\n",
       "      <th>word4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>dɔ̂</td>\n",
       "      <td>a</td>\n",
       "      <td>gâ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>ni</td>\n",
       "      <td>šɨ̂ʔ</td>\n",
       "      <td>ni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>pa</td>\n",
       "      <td>a</td>\n",
       "      <td>nɛ̀ʔ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>pū</td>\n",
       "      <td>a</td>\n",
       "      <td>pi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>šàʔ</td>\n",
       "      <td>a</td>\n",
       "      <td>yûʔ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535</th>\n",
       "      <td>ɨ̄</td>\n",
       "      <td>la</td>\n",
       "      <td>mâ</td>\n",
       "      <td>la</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>ɨ̄</td>\n",
       "      <td>la</td>\n",
       "      <td>mu</td>\n",
       "      <td>la</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1537</th>\n",
       "      <td>ɨ̄</td>\n",
       "      <td>mɨ̀</td>\n",
       "      <td>câʔ</td>\n",
       "      <td>mɨ̀</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538</th>\n",
       "      <td>ɨ̄</td>\n",
       "      <td>qay</td>\n",
       "      <td>mu</td>\n",
       "      <td>qay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539</th>\n",
       "      <td>ɨ̄</td>\n",
       "      <td>ša</td>\n",
       "      <td>mu</td>\n",
       "      <td>ša</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1540 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     word1  word2  word3 word4\n",
       "0        a    dɔ̂      a   gâ\n",
       "1        a     ni  šɨ̂ʔ    ni\n",
       "2        a     pa      a  nɛ̀ʔ\n",
       "3        a    pū      a    pi\n",
       "4        a  šàʔ      a  yûʔ\n",
       "...    ...    ...    ...   ...\n",
       "1535    ɨ̄     la    mâ    la\n",
       "1536    ɨ̄     la     mu    la\n",
       "1537    ɨ̄    mɨ̀   câʔ   mɨ̀\n",
       "1538    ɨ̄    qay     mu   qay\n",
       "1539    ɨ̄    ša     mu   ša\n",
       "\n",
       "[1540 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ABAC = df[df.word1==df.word3]\n",
    "df_ABAC = df_ABAC.rename(columns={'word1': 'rep', 'word2': 'cc1', 'word4': 'cc2'}).drop(columns='word3')\n",
    "df_ABAC['is_ABAC'] = True\n",
    "df_ABAC = df_ABAC[['cc1', 'cc2', 'rep', 'is_ABAC']]\n",
    "\n",
    "df_ABCB = df[df.word2==df.word4]\n",
    "df_ABCB = df_ABCB.rename(columns={'word1': 'cc1', 'word2': 'rep', 'word3': 'cc2'}).drop(columns='word4')\n",
    "df_ABCB['is_ABAC'] = False\n",
    "df_ABCB = df_ABCB[['cc1', 'cc2', 'rep', 'is_ABAC']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cc1</th>\n",
       "      <th>cc2</th>\n",
       "      <th>rep</th>\n",
       "      <th>is_ABAC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dɔ̂</td>\n",
       "      <td>gâ</td>\n",
       "      <td>a</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pa</td>\n",
       "      <td>nɛ̀ʔ</td>\n",
       "      <td>a</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pū</td>\n",
       "      <td>pi</td>\n",
       "      <td>a</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>šàʔ</td>\n",
       "      <td>yûʔ</td>\n",
       "      <td>a</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ví</td>\n",
       "      <td>ni</td>\n",
       "      <td>a</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526</th>\n",
       "      <td>cē</td>\n",
       "      <td>phɔ̂</td>\n",
       "      <td>ɔ̂</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>chî</td>\n",
       "      <td>pâʔ</td>\n",
       "      <td>ɔ̄</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528</th>\n",
       "      <td>chî</td>\n",
       "      <td>phə̀ʔ</td>\n",
       "      <td>ɔ̄</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1529</th>\n",
       "      <td>chî</td>\n",
       "      <td>phə́</td>\n",
       "      <td>ɔ̄</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>cɨ̂</td>\n",
       "      <td>mɛ</td>\n",
       "      <td>ɔ̄</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>728 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        cc1    cc2 rep  is_ABAC\n",
       "0       dɔ̂    gâ   a     True\n",
       "2        pa   nɛ̀ʔ   a     True\n",
       "3       pū     pi   a     True\n",
       "4     šàʔ   yûʔ   a     True\n",
       "5       ví     ni   a     True\n",
       "...     ...    ...  ..      ...\n",
       "1526    cē   phɔ̂  ɔ̂     True\n",
       "1527   chî   pâʔ  ɔ̄     True\n",
       "1528   chî  phə̀ʔ  ɔ̄     True\n",
       "1529   chî   phə́  ɔ̄     True\n",
       "1530    cɨ̂     mɛ  ɔ̄     True\n",
       "\n",
       "[728 rows x 4 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ABAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cc1</th>\n",
       "      <th>cc2</th>\n",
       "      <th>rep</th>\n",
       "      <th>is_ABAC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>šɨ̂ʔ</td>\n",
       "      <td>ni</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>á</td>\n",
       "      <td>yɛ̀</td>\n",
       "      <td>qhɔ</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>bâʔ</td>\n",
       "      <td>vê</td>\n",
       "      <td>ɨ̄</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>bè</td>\n",
       "      <td>lɔ̂</td>\n",
       "      <td>tù</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>bè</td>\n",
       "      <td>lɔ̂</td>\n",
       "      <td>ve</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535</th>\n",
       "      <td>ɨ̄</td>\n",
       "      <td>mâ</td>\n",
       "      <td>la</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>ɨ̄</td>\n",
       "      <td>mu</td>\n",
       "      <td>la</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1537</th>\n",
       "      <td>ɨ̄</td>\n",
       "      <td>câʔ</td>\n",
       "      <td>mɨ̀</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538</th>\n",
       "      <td>ɨ̄</td>\n",
       "      <td>mu</td>\n",
       "      <td>qay</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539</th>\n",
       "      <td>ɨ̄</td>\n",
       "      <td>mu</td>\n",
       "      <td>ša</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>812 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cc1    cc2  rep  is_ABAC\n",
       "1        a  šɨ̂ʔ   ni    False\n",
       "10      á    yɛ̀  qhɔ    False\n",
       "15    bâʔ    vê   ɨ̄    False\n",
       "16     bè    lɔ̂  tù    False\n",
       "17     bè    lɔ̂   ve    False\n",
       "...    ...    ...  ...      ...\n",
       "1535    ɨ̄    mâ   la    False\n",
       "1536    ɨ̄     mu   la    False\n",
       "1537    ɨ̄   câʔ  mɨ̀    False\n",
       "1538    ɨ̄     mu  qay    False\n",
       "1539    ɨ̄     mu  ša    False\n",
       "\n",
       "[812 rows x 4 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ABCB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bothforms = pd.concat([df_ABAC, df_ABCB], names=['cc1', 'cc2', 'rep', 'is_ABAC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABCB phrases\n",
      "460 unique BC pairs\n",
      "most common 10 make up 16.75% of EEs\n",
      "most common 30 make up 33.37% of EEs\n",
      "most common 50 make up 42.00% of EEs\n",
      "most common 100 make up 55.05% of EEs\n",
      "most common 300 make up 80.30% of EEs\n",
      "ABAC phrases (like hmong dataset)\n",
      "574 unique BC pairs\n",
      "most common 10 make up 7.83% of EEs\n",
      "most common 30 make up 16.62% of EEs\n",
      "most common 50 make up 22.53% of EEs\n",
      "most common 100 make up 34.89% of EEs\n",
      "most common 300 make up 62.36% of EEs\n"
     ]
    }
   ],
   "source": [
    "print('ABCB phrases')\n",
    "bc_counts = Counter(tuple(row) for row in df_ABCB.filter(['word1', 'word3']).to_numpy())\n",
    "num_unique_bc = len(bc_counts)\n",
    "print(num_unique_bc, 'unique BC pairs')\n",
    "for n in (10, 30, 50, 100, 300):\n",
    "    proportion = sum([count for tp, count in bc_counts.most_common(n)]) / len(df_ABCB)\n",
    "    print(f'most common {n} make up {proportion*100:.2f}% of EEs')\n",
    "\n",
    "    \n",
    "print('ABAC phrases (like hmong dataset)')\n",
    "bc_counts = Counter(tuple(row) for row in df_ABAC.filter(['word2', 'word4']).to_numpy())\n",
    "num_unique_bc = len(bc_counts)\n",
    "print(num_unique_bc, 'unique BC pairs')\n",
    "for n in (10, 30, 50, 100, 300):\n",
    "    proportion = sum([count for tp, count in bc_counts.most_common(n)]) / len(df_ABAC)\n",
    "    print(f'most common {n} make up {proportion*100:.2f}% of EEs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of unique pairs is a bit flatter than Hmong, but not by too much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABAC phrases\n",
      "there are 28/2=14.0 words with both orders attested\n",
      "ABCB phrases\n",
      "there are 24/2=12.0 words with both orders attested\n"
     ]
    }
   ],
   "source": [
    "print(\"ABAC phrases\")\n",
    "cntr = 0\n",
    "for i, (word1, word2, word3, word4) in df_ABAC.iterrows():\n",
    "    other_order = df[(df.word1==word1) & (df.word2==word4) & (df.word4==word2)]\n",
    "    if len(other_order) > 0:\n",
    "#         print(i, word1, word2, word3, word4)\n",
    "        cntr += 1\n",
    "print(f\"there are {cntr}/2={cntr/2} words with both orders attested\")\n",
    "\n",
    "print(\"ABCB phrases\")\n",
    "cntr = 0\n",
    "for i, (word1, word2, word3, word4) in df_ABCB.iterrows():\n",
    "    other_order = df[(df.word2==word2) & (df.word1==word3) & (df.word3==word1)]\n",
    "    if len(other_order) > 0:\n",
    "#         print(i, word1, word2, word3, word4)\n",
    "        cntr += 1\n",
    "print(f\"there are {cntr}/2={cntr/2} words with both orders attested\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "647 good ones for ABAC, 753 good ones for ABCB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libraries.lahu_jam.lahu_jam_regex import LAHU_REGEX as lahu\n",
    "def is_valid_syl(syl):\n",
    "    m = lahu.match(syl)\n",
    "    if m:\n",
    "        ons, rhy, ton = m.group(\"ons\"), m.group(\"rhy\"), m.group(\"ton\")\n",
    "        return ons+rhy+ton == syl\n",
    "    return False\n",
    "\n",
    "def remove_invalid_data(df0):\n",
    "    df = df0.copy()\n",
    "    c = 0\n",
    "    for i, (cc1, cc2, rep, form) in df.iterrows():\n",
    "        if not all(is_valid_syl(w) for w in (cc1, cc2, rep)):\n",
    "            df.drop(i, inplace=True)\n",
    "        else:\n",
    "            c += 1\n",
    "    print(c, 'good ones')\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def add_unattested_data(df0):\n",
    "    df = df0.copy()\n",
    "    # for each (cc1, cc2) phrase, add (cc2, cc1) phrase\n",
    "    unique_order_indices = []\n",
    "    for i, (cc1, cc2, rep, form) in df.iterrows():\n",
    "        other_order = df[(df.rep==rep) & (df.cc1==cc2) & (df.cc2==cc1)]\n",
    "        if len(other_order) == 0:\n",
    "            unique_order_indices.append(i)\n",
    "    df['attested'] = True\n",
    "    unattested = df.rename(columns={'cc1': 'cc2', 'cc2': 'cc1'}).iloc[unique_order_indices]\n",
    "    unattested['attested'] = False\n",
    "    print(f'len of attested {len(df)}, len of unattested {len(unattested)}')\n",
    "    return df.append(unattested, ignore_index=True)\n",
    "\n",
    "def add_onehot_features(df0, features, tones, rhymes, onsets):\n",
    "    df = df0.copy()\n",
    "#     if 'panphon' in features:\n",
    "#         epi = epitran.Epitran('hmn_Latn')\n",
    "#         ft = panphon.FeatureTable()\n",
    "\n",
    "    for wi in ('cc1', 'cc2', 'rep'):\n",
    "        if 'ton' in features:\n",
    "            for ton in tones:\n",
    "                df[f'{wi}_ton_a{ton}'] = df[wi].apply(lambda syl: lahu.match(syl).group(\"ton\")==ton)\n",
    "        if 'rhy' in features:\n",
    "            for rhy in rhymes:\n",
    "                df[f'{wi}_rhy_{rhy}'] = df[wi].apply(lambda syl: lahu.match(syl).group(\"rhy\")==rhy)\n",
    "        if 'ons' in features:\n",
    "            for ons in onsets:\n",
    "                df[f'{wi}_ons_{ons}'] = df[wi].apply(lambda syl: lahu.match(syl).group(\"ons\")==ons)\n",
    "#         if 'panphon' in features:\n",
    "#             wordi_feats = df[f'word{i}'].apply(lambda syl: ft.bag_of_features(epi.transliterate(syl)))\n",
    "#             panphon_names = [f'w{i}_{sign}{n}' for n in ft.names for sign in ('+', '0', '-')]\n",
    "\n",
    "#             df = pd.merge(\n",
    "#                     df,\n",
    "#                     pd.DataFrame(wordi_feats.tolist(), index=df.index, columns=panphon_names),\n",
    "#                     left_index=True, right_index=True)\n",
    "\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1400 good ones\n"
     ]
    }
   ],
   "source": [
    "use_features = 'ton_rhy_ons'  ## change me\n",
    "df_valid = remove_invalid_data(df_bothforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all possible onsets: Counter({'c': 327, 'š': 325, 'm': 307, 'l': 262, 't': 237, '': 226, 'n': 221, 'v': 212, 'p': 204, 'k': 199, 'h': 199, 'ph': 164, 'qh': 155, 'ch': 152, 'y': 150, 'd': 149, 'q': 125, 'kh': 117, 'g̈': 108, 'b': 98, 'j': 71, 'g': 65, 'th': 64, 'ŋ': 34, 'f': 29}) 25\n",
      "all possible rhymes: Counter({'a': 1211, 'ɔ': 760, 'i': 410, 'ɛ': 402, 'ɨ': 379, 'u': 374, 'e': 306, 'o': 212, 'ə': 146}) 9\n",
      "all possible tones: ['â', 'a', 'ā', 'àʔ', 'á', 'à', 'âʔ'] 7\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "all_syllables = df_valid[\"cc1\"].tolist() + df_valid[\"cc2\"].tolist() + df_valid[\"rep\"].tolist()\n",
    "onsets, rhymes, tones = Counter(), Counter(), Counter()\n",
    "for syl in all_syllables:\n",
    "    m = lahu.match(syl)\n",
    "    ons, rhy, ton = m.group(\"ons\"), m.group(\"rhy\"), m.group(\"ton\")\n",
    "    \n",
    "    onsets[ons] += 1\n",
    "    rhymes[rhy] += 1\n",
    "    tones[ton] += 1\n",
    "    \n",
    "print(\"all possible onsets:\", onsets, len(onsets))\n",
    "print(\"all possible rhymes:\", rhymes, len(rhymes))\n",
    "print(\"all possible tones:\", ['a'+t for t in tones], len(tones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of attested 1400, len of unattested 1348\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_ABAC</th>\n",
       "      <th>attested</th>\n",
       "      <th>cc1_ton_â</th>\n",
       "      <th>cc1_ton_a</th>\n",
       "      <th>cc1_ton_ā</th>\n",
       "      <th>cc1_ton_àʔ</th>\n",
       "      <th>cc1_ton_á</th>\n",
       "      <th>cc1_ton_à</th>\n",
       "      <th>cc1_ton_âʔ</th>\n",
       "      <th>cc1_rhy_ɔ</th>\n",
       "      <th>...</th>\n",
       "      <th>rep_ons_t</th>\n",
       "      <th>rep_ons_g</th>\n",
       "      <th>rep_ons_</th>\n",
       "      <th>rep_ons_b</th>\n",
       "      <th>rep_ons_g̈</th>\n",
       "      <th>rep_ons_kh</th>\n",
       "      <th>rep_ons_k</th>\n",
       "      <th>rep_ons_h</th>\n",
       "      <th>rep_ons_ŋ</th>\n",
       "      <th>rep_ons_f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2743</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2744</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2745</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2746</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2747</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2748 rows × 125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      is_ABAC  attested  cc1_ton_â  cc1_ton_a  cc1_ton_ā  cc1_ton_àʔ  \\\n",
       "0        True      True        True      False       False        False   \n",
       "1        True      True       False       True       False        False   \n",
       "2        True      True       False      False        True        False   \n",
       "3        True      True       False      False       False         True   \n",
       "4        True      True       False      False       False        False   \n",
       "...       ...       ...         ...        ...         ...          ...   \n",
       "2743    False     False       False       True       False        False   \n",
       "2744    False     False        True      False       False        False   \n",
       "2745    False     False       False       True       False        False   \n",
       "2746    False     False       False      False       False        False   \n",
       "2747    False     False       False       True       False        False   \n",
       "\n",
       "      cc1_ton_á  cc1_ton_à  cc1_ton_âʔ  cc1_rhy_ɔ  ...  rep_ons_t  \\\n",
       "0          False       False        False       True  ...      False   \n",
       "1          False       False        False      False  ...      False   \n",
       "2          False       False        False      False  ...      False   \n",
       "3          False       False        False      False  ...      False   \n",
       "4           True       False        False      False  ...      False   \n",
       "...          ...         ...          ...        ...  ...        ...   \n",
       "2743       False       False        False      False  ...      False   \n",
       "2744       False       False        False      False  ...      False   \n",
       "2745       False       False        False      False  ...      False   \n",
       "2746       False       False         True      False  ...      False   \n",
       "2747       False       False        False      False  ...      False   \n",
       "\n",
       "      rep_ons_g  rep_ons_  rep_ons_b  rep_ons_g̈  rep_ons_kh  rep_ons_k  \\\n",
       "0         False      True      False       False       False      False   \n",
       "1         False      True      False       False       False      False   \n",
       "2         False      True      False       False       False      False   \n",
       "3         False      True      False       False       False      False   \n",
       "4         False      True      False       False       False      False   \n",
       "...         ...       ...        ...         ...         ...        ...   \n",
       "2743      False     False      False       False       False       True   \n",
       "2744      False     False      False       False       False      False   \n",
       "2745      False     False      False       False       False      False   \n",
       "2746      False     False      False       False       False      False   \n",
       "2747      False     False      False       False       False      False   \n",
       "\n",
       "      rep_ons_h  rep_ons_ŋ  rep_ons_f  \n",
       "0         False      False      False  \n",
       "1         False      False      False  \n",
       "2         False      False      False  \n",
       "3         False      False      False  \n",
       "4         False      False      False  \n",
       "...         ...        ...        ...  \n",
       "2743      False      False      False  \n",
       "2744      False      False      False  \n",
       "2745      False      False      False  \n",
       "2746      False      False      False  \n",
       "2747      False      False      False  \n",
       "\n",
       "[2748 rows x 125 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded_df = add_onehot_features(add_unattested_data(df_valid), \n",
    "                                 use_features, tones, rhymes, onsets).drop(columns=['cc1', 'cc2', 'rep'])\n",
    "expanded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2748, 124) (2748,)\n"
     ]
    }
   ],
   "source": [
    "X = expanded_df.drop(columns=['attested']).to_numpy()\n",
    "y = expanded_df['attested'].to_numpy()\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use X and y to train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectFromModel, SelectKBest, chi2\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from scipy.stats import describe\n",
    "\n",
    "def train_test(clf, X, y):\n",
    "    accs = []\n",
    "    for rnd in range(50):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=rnd)\n",
    "        clf_train = clf.fit(X_train, y_train)\n",
    "        accs.append(clf_train.score(X_test, y_test))\n",
    "\n",
    "    print(describe(accs))\n",
    "    \n",
    "    \n",
    "def select_features_from_model(clf, X, y, method='from_model'):\n",
    "    clf_best = None\n",
    "    best_accs = 0\n",
    "    if clf.__class__.__name__ == 'SVC':\n",
    "        num_features_to_try = (260, 240, 220, 200, 180, 160, 140, 120, 100, 80, 60, 40)\n",
    "    else:\n",
    "        num_features_to_try = (120, 110, 100, 90, 80, 70, 60, 50, 40, 35, 30, 25, 20, 15, 10)\n",
    "    for t in num_features_to_try:\n",
    "        if method == 'from_model':\n",
    "            model = SelectFromModel(clf, prefit=True, threshold=-np.inf, max_features=t)\n",
    "            X_new = model.transform(X)\n",
    "            #     print(f\"new feature set has {X_new.shape[1]} features\")\n",
    "        elif method == 'chi2':\n",
    "            if t > X.shape[1]: continue\n",
    "            X_new = SelectKBest(chi2, k=t).fit_transform(X, y)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        print(X_new.shape[1], end=', ')\n",
    "        clf_new = DecisionTreeClassifier(criterion='entropy', random_state=0).fit(X_new, y)\n",
    "        #     print(f\"full training accuracy is {clf_new.score(X_new, y):.3f}\")\n",
    "        print(f\"{clf_new.score(X_new, y):.3f}\", end=', ')\n",
    "\n",
    "        accs = []\n",
    "        prns = []\n",
    "        rcls = []\n",
    "        for rnd in range(10):\n",
    "            X_new_train, X_new_test, y_train, y_test = train_test_split(X_new, y, test_size=0.3, random_state=rnd)\n",
    "            clf_train = DecisionTreeClassifier(criterion='entropy', random_state=rnd).fit(X_new_train, y_train)\n",
    "            accs.append(clf_train.score(X_new_test, y_test))\n",
    "            y_predict = clf_train.predict(X_new_test)\n",
    "            prns.append(precision_score(y_test, y_predict))\n",
    "            rcls.append(recall_score(y_test, y_predict))\n",
    "        #     print(f\"average test accuracy is {np.mean(accs):.3f}\")\n",
    "        #     print(\"=\"*40)\n",
    "        mean_accs = np.mean(accs)\n",
    "        mean_prns = np.mean(prns)\n",
    "        mean_rcls = np.mean(rcls)\n",
    "        if mean_accs > best_accs:\n",
    "            best_accs = mean_accs\n",
    "            clf_best = clf_new\n",
    "        print(f\"{mean_accs:.3f}, prn {mean_prns:.3f}, rcl {mean_rcls:.3f}\")\n",
    "\n",
    "    return best_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DescribeResult(nobs=50, minmax=(0.7551515151515151, 0.8145454545454546), mean=0.7816727272727274, variance=0.00017592713779726764, skewness=0.28349393222629893, kurtosis=-0.25832500079211806)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# clf = DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
    "clf = SVC()\n",
    "train_test(clf, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120, 1.000, 0.753, prn 0.755, rcl 0.758\n",
      "100, 0.999, 0.761, prn 0.760, rcl 0.770\n",
      "80, 0.992, 0.773, prn 0.779, rcl 0.770\n",
      "60, 0.985, 0.780, prn 0.784, rcl 0.779\n",
      "40, 0.934, 0.755, prn 0.769, rcl 0.737\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.78"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_features_from_model(clf, X, y, method='chi2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot in /home/cuichenx/anaconda3/envs/py38/lib/python3.8/site-packages (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in /home/cuichenx/anaconda3/envs/py38/lib/python3.8/site-packages (from pydot) (2.4.7)\n",
      "Requirement already satisfied: graphviz in /home/cuichenx/anaconda3/envs/py38/lib/python3.8/site-packages (0.17)\n"
     ]
    }
   ],
   "source": [
    "!pip install pydot\n",
    "!pip install graphviz\n",
    "# note: also need to install graphviz on your system: https://www.graphviz.org/\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot\n",
    "import re\n",
    "import graphviz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = expanded_df.columns.to_list()\n",
    "feature_names.remove('attested')\n",
    "class_names = ['FAKE', 'ATT']\n",
    "\n",
    "d = 15 # max depth. Use None if unlimited\n",
    "\n",
    "# visualize tree trained on full training set\n",
    "clf = clf.fit(X, y)\n",
    "\n",
    "fname = f'../out/Lahu_{use_features}_{d or \"\"}.dot'\n",
    "export_graphviz(clf, \n",
    "                out_file=fname, \n",
    "                impurity=False, \n",
    "                feature_names=feature_names,\n",
    "                class_names=class_names,\n",
    "                max_depth=d)\n",
    "\n",
    "f = pydot.graph_from_dot_file(fname)[0].to_string()\n",
    "# print(len(f), '\\n', f[:1000])\n",
    "# f = re.sub(r'(\\\\nvalue = \\[.*?\\])', '', f)  # get rid of nvalue = [anychar, lazy]\n",
    "# f = f.replace(' <= 0.5', '?')  # change decision to a question\n",
    "# f = f.replace('headlabel=\"True\"', 'headlabel=\"No\"')  # change to yes no rather than <=0.5 true false\n",
    "# f = f.replace('headlabel=\"False\"', 'headlabel=\"Yes\"')\n",
    "# f = f.replace(R'samples = 1\\nclass = ', R'***\\n')  # change text of leaf node\n",
    "# print(\"============================\")\n",
    "# print(len(f), '\\n', f[:1000])\n",
    "\n",
    "with open(fname, 'w') as file:\n",
    "    file.write(f)\n",
    "    \n",
    "savepath = graphviz.render('dot', 'png', fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['word1', 'word2', 'word3', 'word4']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py38] *",
   "language": "python",
   "name": "conda-env-py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
