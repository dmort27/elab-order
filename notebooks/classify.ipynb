{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from libraries.hmong_rpa.rpa_regex import RPA_SYLLABLE as rpa\n",
    "import epitran, panphon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../scripts/elabs_extracted.csv\", quoting=csv.QUOTE_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>word3</th>\n",
       "      <th>word4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vuag</td>\n",
       "      <td>ub</td>\n",
       "      <td>vuag</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xaiv</td>\n",
       "      <td>ntsej</td>\n",
       "      <td>xaiv</td>\n",
       "      <td>muag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qhov</td>\n",
       "      <td>phem</td>\n",
       "      <td>qhov</td>\n",
       "      <td>zoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kev</td>\n",
       "      <td>neej</td>\n",
       "      <td>kev</td>\n",
       "      <td>tsav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tej</td>\n",
       "      <td>nom</td>\n",
       "      <td>tej</td>\n",
       "      <td>tswv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3248</th>\n",
       "      <td>khu</td>\n",
       "      <td>mob</td>\n",
       "      <td>khu</td>\n",
       "      <td>nkees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3249</th>\n",
       "      <td>cam</td>\n",
       "      <td>mus</td>\n",
       "      <td>cam</td>\n",
       "      <td>los</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3250</th>\n",
       "      <td>me</td>\n",
       "      <td>tes</td>\n",
       "      <td>me</td>\n",
       "      <td>taw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3251</th>\n",
       "      <td>dig</td>\n",
       "      <td>lwj</td>\n",
       "      <td>dig</td>\n",
       "      <td>liam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3252</th>\n",
       "      <td>noj</td>\n",
       "      <td>nyuj</td>\n",
       "      <td>noj</td>\n",
       "      <td>twm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3253 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     word1  word2 word3  word4\n",
       "0     vuag     ub  vuag     no\n",
       "1     xaiv  ntsej  xaiv   muag\n",
       "2     qhov   phem  qhov    zoo\n",
       "3      kev   neej   kev   tsav\n",
       "4      tej    nom   tej   tswv\n",
       "...    ...    ...   ...    ...\n",
       "3248   khu    mob   khu  nkees\n",
       "3249   cam    mus   cam    los\n",
       "3250    me    tes    me    taw\n",
       "3251   dig    lwj   dig   liam\n",
       "3252   noj   nyuj   noj    twm\n",
       "\n",
       "[3253 rows x 4 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word order classification\n",
    "\n",
    "Before training anything though, how would a rule-based classifier do?\n",
    "\n",
    "Based on the A -> D -> B -> C and 2 -> 1 orderings, the tones should be ordered like this:\n",
    "[j, b, m, s, s/g, v, g, 0]\n",
    "\n",
    "we have to ignore the B2 split here and just work with [j, b, m, s, v, g, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rule_prediction(df0):\n",
    "    def sgn(x):\n",
    "        return 0 if x==0 else x//abs(x)\n",
    "    \n",
    "    df = df0.copy()\n",
    "    orders = {'j': 1,\n",
    "              'b': 2,\n",
    "              'm': 3, 'd': 3,\n",
    "              's': 4,\n",
    "              'v': 5,\n",
    "              'g': 6,\n",
    "              '' : 7}\n",
    "    df['rule_pred'] = (df['word4'].apply(lambda syl: orders[rpa.match(syl).group(\"ton\")]) - \n",
    "                        df['word2'].apply(lambda syl: orders[rpa.match(syl).group(\"ton\")]) )\n",
    "    df['rule_pred'] = df['rule_pred'].apply(sgn)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = add_rule_prediction(df)['rule_pred'].value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 0.8383031048263142\n",
      "Tie: 0.09007070396557024\n",
      "Incorrect: 0.07162619120811559\n",
      "\n",
      "Correct with random guess: 0.8833384568090993\n",
      "Incorrect with random guess: 0.1166615431909007\n"
     ]
    }
   ],
   "source": [
    "print(f'Correct: {res[1]/len(df)}')\n",
    "print(f'Tie: {res[0]/len(df)}')\n",
    "print(f'Incorrect: {res[-1]/len(df)}')\n",
    "print()\n",
    "print(f'Correct with random guess: {res[1]/len(df) + res[0]/len(df)/2}')\n",
    "print(f'Incorrect with random guess: {res[-1]/len(df) + res[0]/len(df)/2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare one hot data\n",
    "\n",
    "add these ton columns to the data, for each $i=1,2,4$:\n",
    "- wi_ton_b\n",
    "- wi_ton_0\n",
    "- wi_ton_s\n",
    "- wi_ton_j\n",
    "- wi_ton_v\n",
    "- wi_ton_m\n",
    "- wi_ton_g\n",
    "\n",
    "Similarly for rhy and ons. There are 7 tones, 14 rhymes, and 58 onsets for Hmong. Since the tones, onset, and rhyme for word1 and word3 are the same, there are a total of $3\\times(7+14+58)=237$ features\n",
    "\n",
    "For natural class features, there are 24 for each of onset, rhyme, and tone, for each of three words, for a total of 24 * 3 * 3 = 216 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all possible onsets: Counter({'t': 932, 'n': 719, 'l': 558, 'ts': 492, 'k': 473, 'p': 447, 'm': 445, '': 366, 's': 363, 'z': 337, 'c': 336, 'tx': 334, 'y': 288, 'd': 276, 'nt': 262, 'h': 248, 'r': 225, 'nts': 210, 'q': 197, 'ny': 176, 'txh': 141, 'ph': 130, 'ch': 122, 'v': 121, 'hl': 119, 'tsh': 115, 'x': 105, 'nc': 100, 'qh': 97, 'kh': 95, 'nr': 94, 'pl': 87, 'th': 85, 'np': 80, 'hm': 74, 'nq': 68, 'nk': 61, 'hn': 59, 'xy': 54, 'ntsh': 46, 'ntxh': 42, 'f': 34, 'dl': 33, 'ntx': 29, 'npl': 25, 'dh': 13, 'nrh': 12, 'ml': 8, 'nqh': 8, 'plh': 3, 'nch': 3, 'rh': 2, 'dlh': 2, 'ndl': 2, 'nkh': 2, 'hny': 2, 'nth': 1, 'nph': 1}) 58\n",
      "all possible rhymes: Counter({'o': 1314, 'u': 1076, 'ua': 1071, 'e': 956, 'a': 932, 'i': 853, 'au': 674, 'aw': 583, 'ia': 563, 'oo': 505, 'w': 417, 'ee': 413, 'ai': 262, 'aa': 140}) 14\n",
      "all possible tones: Counter({'b': 1985, 'j': 1697, '': 1560, 'v': 1424, 's': 1181, 'g': 967, 'm': 931, 'd': 14}) 8\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from collections import Counter\n",
    "all_syllables = df[\"word1\"].tolist() + df[\"word2\"].tolist() + df[\"word4\"].tolist()\n",
    "onsets, rhymes, tones = Counter(), Counter(), Counter()\n",
    "for syl in all_syllables:\n",
    "    m = rpa.match(syl)\n",
    "    ons, rhy, ton = m.group(\"ons\"), m.group(\"rhy\"), m.group(\"ton\")\n",
    "    \n",
    "    onsets[ons] += 1\n",
    "    rhymes[rhy] += 1\n",
    "    tones[ton] += 1\n",
    "    \n",
    "print(\"all possible onsets:\", onsets, len(onsets))\n",
    "print(\"all possible rhymes:\", rhymes, len(rhymes))\n",
    "print(\"all possible tones:\", tones, len(tones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_unattested_data(df0):\n",
    "    df = df0.copy()\n",
    "    # for each ABAC phrase, add ACAB phrase\n",
    "    unique_order_indices = []\n",
    "    for i, (word1, word2, word3, word4) in df.iterrows():\n",
    "        other_order = df[(df.word1==word1) & (df.word2==word4) & (df.word4==word2)]\n",
    "        if len(other_order) == 0:\n",
    "            unique_order_indices.append(i)\n",
    "    df['attested'] = True\n",
    "    unattested = df.rename(columns={'word2': 'word4', 'word4': 'word2'}).iloc[unique_order_indices]\n",
    "    unattested['attested'] = False\n",
    "    print(f'len of attested {len(df)}, len of unattested {len(unattested)}')\n",
    "    return df.append(unattested, ignore_index=True)\n",
    "\n",
    "\n",
    "def add_onehot_features(df0, features='ton'):\n",
    "    df = df0.copy()\n",
    "    # for each of the three (w1 and w3 identical) words, add onehot vector of each tone\n",
    "    if 'panphon' in features:\n",
    "        epi = epitran.Epitran('hmn-Latn')\n",
    "        ft = panphon.FeatureTable()\n",
    "        # ft.bag_of_features(epi.transliterate('ntshoob'))\n",
    "\n",
    "\n",
    "    for i in (1, 2, 4):\n",
    "        if 'ton' in features:\n",
    "            for ton in tones:\n",
    "                if ton == '':\n",
    "                    df[f'w{i}_ton_0'] = df[f'word{i}'].apply(lambda syl: rpa.match(syl).group(\"ton\")=='')\n",
    "                elif ton == 'd': continue\n",
    "                elif ton == 'm':\n",
    "                    df[f'w{i}_ton_m'] = df[f'word{i}'].apply(lambda syl: syl.endswith('m') or syl.endswith('d'))\n",
    "                else:\n",
    "                    df[f'w{i}_ton_{ton}'] = df[f'word{i}'].str.endswith(ton)\n",
    "        if 'rhy' in features:\n",
    "            for rhy in rhymes:\n",
    "                df[f'w{i}_rhy_{rhy}'] = df[f'word{i}'].apply(lambda syl: rpa.match(syl).group(\"rhy\")==rhy)\n",
    "        if 'ons' in features:\n",
    "            for ons in onsets:\n",
    "                df[f'w{i}_ons_{ons}'] = df[f'word{i}'].apply(lambda syl: rpa.match(syl).group(\"ons\")==ons)\n",
    "        if 'panphon' in features:\n",
    "            wordi_feats = df[f'word{i}'].apply(lambda syl: ft.bag_of_features(epi.transliterate(syl)))\n",
    "            panphon_names = [f'w{i}_{sign}{n}' for n in ft.names for sign in ('+', '0', '-')]\n",
    "\n",
    "            df = pd.merge(\n",
    "                    df,\n",
    "                    pd.DataFrame(wordi_feats.tolist(), index=df.index, columns=panphon_names),\n",
    "                    left_index=True, right_index=True)\n",
    "\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of attested 3253, len of unattested 3169\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attested</th>\n",
       "      <th>w1_ton_g</th>\n",
       "      <th>w1_ton_v</th>\n",
       "      <th>w1_ton_j</th>\n",
       "      <th>w1_ton_0</th>\n",
       "      <th>w1_ton_b</th>\n",
       "      <th>w1_ton_s</th>\n",
       "      <th>w1_ton_m</th>\n",
       "      <th>w1_rhy_ua</th>\n",
       "      <th>w1_rhy_ai</th>\n",
       "      <th>...</th>\n",
       "      <th>w4_-tense</th>\n",
       "      <th>w4_+long</th>\n",
       "      <th>w4_0long</th>\n",
       "      <th>w4_-long</th>\n",
       "      <th>w4_+hitone</th>\n",
       "      <th>w4_0hitone</th>\n",
       "      <th>w4_-hitone</th>\n",
       "      <th>w4_+hireg</th>\n",
       "      <th>w4_0hireg</th>\n",
       "      <th>w4_-hireg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6417</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6418</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6419</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6420</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6421</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6422 rows × 454 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      attested  w1_ton_g  w1_ton_v  w1_ton_j  w1_ton_0  w1_ton_b  w1_ton_s  \\\n",
       "0         True      True     False     False     False     False     False   \n",
       "1         True     False      True     False     False     False     False   \n",
       "2         True     False      True     False     False     False     False   \n",
       "3         True     False      True     False     False     False     False   \n",
       "4         True     False     False      True     False     False     False   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "6417     False     False     False     False      True     False     False   \n",
       "6418     False     False     False     False     False     False     False   \n",
       "6419     False     False     False     False      True     False     False   \n",
       "6420     False      True     False     False     False     False     False   \n",
       "6421     False     False     False      True     False     False     False   \n",
       "\n",
       "      w1_ton_m  w1_rhy_ua  w1_rhy_ai  ...  w4_-tense  w4_+long  w4_0long  \\\n",
       "0        False       True      False  ...          1         0         1   \n",
       "1        False      False       True  ...          1         0         2   \n",
       "2        False      False      False  ...          1         0         1   \n",
       "3        False      False      False  ...          0         0         2   \n",
       "4        False      False      False  ...          0         0         2   \n",
       "...        ...        ...        ...  ...        ...       ...       ...   \n",
       "6417     False      False      False  ...          1         0         1   \n",
       "6418      True      False      False  ...          0         0         1   \n",
       "6419     False      False      False  ...          0         0         1   \n",
       "6420     False      False      False  ...          0         0         2   \n",
       "6421     False      False      False  ...          0         0         2   \n",
       "\n",
       "      w4_-long  w4_+hitone  w4_0hitone  w4_-hitone  w4_+hireg  w4_0hireg  \\\n",
       "0            2           0           3           0          0          3   \n",
       "1            3           0           4           1          0          4   \n",
       "2            2           0           3           0          0          3   \n",
       "3            2           1           3           0          1          3   \n",
       "4            2           1           3           0          1          3   \n",
       "...        ...         ...         ...         ...        ...        ...   \n",
       "6417         2           1           2           0          1          2   \n",
       "6418         2           1           2           0          0          2   \n",
       "6419         2           1           2           0          0          2   \n",
       "6420         2           2           2           0          1          2   \n",
       "6421         2           2           2           0          1          2   \n",
       "\n",
       "      w4_-hireg  \n",
       "0             0  \n",
       "1             1  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "...         ...  \n",
       "6417          0  \n",
       "6418          1  \n",
       "6419          1  \n",
       "6420          1  \n",
       "6421          1  \n",
       "\n",
       "[6422 rows x 454 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_features = 'ton_rhy_ons_panphon'  ## change me\n",
    "expanded_df = add_onehot_features(add_unattested_data(df), \n",
    "                                 features=use_features).drop(columns=['word1', 'word2', 'word3', 'word4'])\n",
    "expanded_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3253 attested words, 3169 of which do not have the alternate order attested, for a total of 6422 rows\n",
    "Without Panphon features, there are 238 columns, for 237 features and 1 label column.\n",
    "With Panphon features, there are $237 + 72\\times3 + 1 = 454$ columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6422, 453) (6422,)\n"
     ]
    }
   ],
   "source": [
    "X = expanded_df.drop(columns=['attested']).to_numpy()\n",
    "y = expanded_df['attested'].to_numpy()\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attested': True,\n",
       " 'w1_ton_g': True,\n",
       " 'w1_ton_v': False,\n",
       " 'w1_ton_j': False,\n",
       " 'w1_ton_0': False,\n",
       " 'w1_ton_b': False,\n",
       " 'w1_ton_s': False,\n",
       " 'w1_ton_m': False,\n",
       " 'w1_rhy_ua': True,\n",
       " 'w1_rhy_ai': False,\n",
       " 'w1_rhy_o': False,\n",
       " 'w1_rhy_e': False,\n",
       " 'w1_rhy_i': False,\n",
       " 'w1_rhy_u': False,\n",
       " 'w1_rhy_au': False,\n",
       " 'w1_rhy_aw': False,\n",
       " 'w1_rhy_ee': False,\n",
       " 'w1_rhy_w': False,\n",
       " 'w1_rhy_ia': False,\n",
       " 'w1_rhy_a': False,\n",
       " 'w1_rhy_oo': False,\n",
       " 'w1_rhy_aa': False,\n",
       " 'w1_ons_v': True,\n",
       " 'w1_ons_x': False,\n",
       " 'w1_ons_qh': False,\n",
       " 'w1_ons_k': False,\n",
       " 'w1_ons_t': False,\n",
       " 'w1_ons_txh': False,\n",
       " 'w1_ons_': False,\n",
       " 'w1_ons_nt': False,\n",
       " 'w1_ons_p': False,\n",
       " 'w1_ons_s': False,\n",
       " 'w1_ons_y': False,\n",
       " 'w1_ons_nq': False,\n",
       " 'w1_ons_n': False,\n",
       " 'w1_ons_tsh': False,\n",
       " 'w1_ons_th': False,\n",
       " 'w1_ons_ny': False,\n",
       " 'w1_ons_c': False,\n",
       " 'w1_ons_kh': False,\n",
       " 'w1_ons_l': False,\n",
       " 'w1_ons_ts': False,\n",
       " 'w1_ons_tx': False,\n",
       " 'w1_ons_h': False,\n",
       " 'w1_ons_m': False,\n",
       " 'w1_ons_r': False,\n",
       " 'w1_ons_nr': False,\n",
       " 'w1_ons_d': False,\n",
       " 'w1_ons_z': False,\n",
       " 'w1_ons_np': False,\n",
       " 'w1_ons_nrh': False,\n",
       " 'w1_ons_hl': False,\n",
       " 'w1_ons_ch': False,\n",
       " 'w1_ons_hm': False,\n",
       " 'w1_ons_ntx': False,\n",
       " 'w1_ons_nts': False,\n",
       " 'w1_ons_ntsh': False,\n",
       " 'w1_ons_hn': False,\n",
       " 'w1_ons_q': False,\n",
       " 'w1_ons_dh': False,\n",
       " 'w1_ons_pl': False,\n",
       " 'w1_ons_dl': False,\n",
       " 'w1_ons_ml': False,\n",
       " 'w1_ons_plh': False,\n",
       " 'w1_ons_nk': False,\n",
       " 'w1_ons_nc': False,\n",
       " 'w1_ons_npl': False,\n",
       " 'w1_ons_nch': False,\n",
       " 'w1_ons_ntxh': False,\n",
       " 'w1_ons_f': False,\n",
       " 'w1_ons_xy': False,\n",
       " 'w1_ons_ph': False,\n",
       " 'w1_ons_rh': False,\n",
       " 'w1_ons_nth': False,\n",
       " 'w1_ons_dlh': False,\n",
       " 'w1_ons_nph': False,\n",
       " 'w1_ons_ndl': False,\n",
       " 'w1_ons_nkh': False,\n",
       " 'w1_ons_nqh': False,\n",
       " 'w1_ons_hny': False,\n",
       " 'w1_+syl': 2,\n",
       " 'w1_0syl': 2,\n",
       " 'w1_-syl': 1,\n",
       " 'w1_+son': 2,\n",
       " 'w1_0son': 2,\n",
       " 'w1_-son': 1,\n",
       " 'w1_+cons': 1,\n",
       " 'w1_0cons': 2,\n",
       " 'w1_-cons': 2,\n",
       " 'w1_+cont': 3,\n",
       " 'w1_0cont': 2,\n",
       " 'w1_-cont': 0,\n",
       " 'w1_+delrel': 0,\n",
       " 'w1_0delrel': 2,\n",
       " 'w1_-delrel': 3,\n",
       " 'w1_+lat': 0,\n",
       " 'w1_0lat': 2,\n",
       " 'w1_-lat': 3,\n",
       " 'w1_+nas': 0,\n",
       " 'w1_0nas': 2,\n",
       " 'w1_-nas': 3,\n",
       " 'w1_+strid': 1,\n",
       " 'w1_0strid': 4,\n",
       " 'w1_-strid': 0,\n",
       " 'w1_+voi': 3,\n",
       " 'w1_0voi': 2,\n",
       " 'w1_-voi': 0,\n",
       " 'w1_+sg': 0,\n",
       " 'w1_0sg': 2,\n",
       " 'w1_-sg': 3,\n",
       " 'w1_+cg': 0,\n",
       " 'w1_0cg': 2,\n",
       " 'w1_-cg': 3,\n",
       " 'w1_+ant': 1,\n",
       " 'w1_0ant': 4,\n",
       " 'w1_-ant': 0,\n",
       " 'w1_+cor': 0,\n",
       " 'w1_0cor': 2,\n",
       " 'w1_-cor': 3,\n",
       " 'w1_+distr': 0,\n",
       " 'w1_0distr': 5,\n",
       " 'w1_-distr': 0,\n",
       " 'w1_+lab': 2,\n",
       " 'w1_0lab': 2,\n",
       " 'w1_-lab': 1,\n",
       " 'w1_+hi': 1,\n",
       " 'w1_0hi': 2,\n",
       " 'w1_-hi': 2,\n",
       " 'w1_+lo': 0,\n",
       " 'w1_0lo': 2,\n",
       " 'w1_-lo': 3,\n",
       " 'w1_+back': 2,\n",
       " 'w1_0back': 2,\n",
       " 'w1_-back': 1,\n",
       " 'w1_+round': 1,\n",
       " 'w1_0round': 2,\n",
       " 'w1_-round': 2,\n",
       " 'w1_+velaric': 0,\n",
       " 'w1_0velaric': 2,\n",
       " 'w1_-velaric': 3,\n",
       " 'w1_+tense': 1,\n",
       " 'w1_0tense': 3,\n",
       " 'w1_-tense': 1,\n",
       " 'w1_+long': 0,\n",
       " 'w1_0long': 2,\n",
       " 'w1_-long': 3,\n",
       " 'w1_+hitone': 0,\n",
       " 'w1_0hitone': 4,\n",
       " 'w1_-hitone': 1,\n",
       " 'w1_+hireg': 0,\n",
       " 'w1_0hireg': 4,\n",
       " 'w1_-hireg': 1,\n",
       " 'w2_ton_g': False,\n",
       " 'w2_ton_v': False,\n",
       " 'w2_ton_j': False,\n",
       " 'w2_ton_0': False,\n",
       " 'w2_ton_b': True,\n",
       " 'w2_ton_s': False,\n",
       " 'w2_ton_m': False,\n",
       " 'w2_rhy_ua': False,\n",
       " 'w2_rhy_ai': False,\n",
       " 'w2_rhy_o': False,\n",
       " 'w2_rhy_e': False,\n",
       " 'w2_rhy_i': False,\n",
       " 'w2_rhy_u': True,\n",
       " 'w2_rhy_au': False,\n",
       " 'w2_rhy_aw': False,\n",
       " 'w2_rhy_ee': False,\n",
       " 'w2_rhy_w': False,\n",
       " 'w2_rhy_ia': False,\n",
       " 'w2_rhy_a': False,\n",
       " 'w2_rhy_oo': False,\n",
       " 'w2_rhy_aa': False,\n",
       " 'w2_ons_v': False,\n",
       " 'w2_ons_x': False,\n",
       " 'w2_ons_qh': False,\n",
       " 'w2_ons_k': False,\n",
       " 'w2_ons_t': False,\n",
       " 'w2_ons_txh': False,\n",
       " 'w2_ons_': True,\n",
       " 'w2_ons_nt': False,\n",
       " 'w2_ons_p': False,\n",
       " 'w2_ons_s': False,\n",
       " 'w2_ons_y': False,\n",
       " 'w2_ons_nq': False,\n",
       " 'w2_ons_n': False,\n",
       " 'w2_ons_tsh': False,\n",
       " 'w2_ons_th': False,\n",
       " 'w2_ons_ny': False,\n",
       " 'w2_ons_c': False,\n",
       " 'w2_ons_kh': False,\n",
       " 'w2_ons_l': False,\n",
       " 'w2_ons_ts': False,\n",
       " 'w2_ons_tx': False,\n",
       " 'w2_ons_h': False,\n",
       " 'w2_ons_m': False,\n",
       " 'w2_ons_r': False,\n",
       " 'w2_ons_nr': False,\n",
       " 'w2_ons_d': False,\n",
       " 'w2_ons_z': False,\n",
       " 'w2_ons_np': False,\n",
       " 'w2_ons_nrh': False,\n",
       " 'w2_ons_hl': False,\n",
       " 'w2_ons_ch': False,\n",
       " 'w2_ons_hm': False,\n",
       " 'w2_ons_ntx': False,\n",
       " 'w2_ons_nts': False,\n",
       " 'w2_ons_ntsh': False,\n",
       " 'w2_ons_hn': False,\n",
       " 'w2_ons_q': False,\n",
       " 'w2_ons_dh': False,\n",
       " 'w2_ons_pl': False,\n",
       " 'w2_ons_dl': False,\n",
       " 'w2_ons_ml': False,\n",
       " 'w2_ons_plh': False,\n",
       " 'w2_ons_nk': False,\n",
       " 'w2_ons_nc': False,\n",
       " 'w2_ons_npl': False,\n",
       " 'w2_ons_nch': False,\n",
       " 'w2_ons_ntxh': False,\n",
       " 'w2_ons_f': False,\n",
       " 'w2_ons_xy': False,\n",
       " 'w2_ons_ph': False,\n",
       " 'w2_ons_rh': False,\n",
       " 'w2_ons_nth': False,\n",
       " 'w2_ons_dlh': False,\n",
       " 'w2_ons_nph': False,\n",
       " 'w2_ons_ndl': False,\n",
       " 'w2_ons_nkh': False,\n",
       " 'w2_ons_nqh': False,\n",
       " 'w2_ons_hny': False,\n",
       " 'w2_+syl': 1,\n",
       " 'w2_0syl': 1,\n",
       " 'w2_-syl': 0,\n",
       " 'w2_+son': 1,\n",
       " 'w2_0son': 1,\n",
       " 'w2_-son': 0,\n",
       " 'w2_+cons': 0,\n",
       " 'w2_0cons': 1,\n",
       " 'w2_-cons': 1,\n",
       " 'w2_+cont': 1,\n",
       " 'w2_0cont': 1,\n",
       " 'w2_-cont': 0,\n",
       " 'w2_+delrel': 0,\n",
       " 'w2_0delrel': 1,\n",
       " 'w2_-delrel': 1,\n",
       " 'w2_+lat': 0,\n",
       " 'w2_0lat': 1,\n",
       " 'w2_-lat': 1,\n",
       " 'w2_+nas': 0,\n",
       " 'w2_0nas': 1,\n",
       " 'w2_-nas': 1,\n",
       " 'w2_+strid': 0,\n",
       " 'w2_0strid': 2,\n",
       " 'w2_-strid': 0,\n",
       " 'w2_+voi': 1,\n",
       " 'w2_0voi': 1,\n",
       " 'w2_-voi': 0,\n",
       " 'w2_+sg': 0,\n",
       " 'w2_0sg': 1,\n",
       " 'w2_-sg': 1,\n",
       " 'w2_+cg': 0,\n",
       " 'w2_0cg': 1,\n",
       " 'w2_-cg': 1,\n",
       " 'w2_+ant': 0,\n",
       " 'w2_0ant': 2,\n",
       " 'w2_-ant': 0,\n",
       " 'w2_+cor': 0,\n",
       " 'w2_0cor': 1,\n",
       " 'w2_-cor': 1,\n",
       " 'w2_+distr': 0,\n",
       " 'w2_0distr': 2,\n",
       " 'w2_-distr': 0,\n",
       " 'w2_+lab': 1,\n",
       " 'w2_0lab': 1,\n",
       " 'w2_-lab': 0,\n",
       " 'w2_+hi': 1,\n",
       " 'w2_0hi': 1,\n",
       " 'w2_-hi': 0,\n",
       " 'w2_+lo': 0,\n",
       " 'w2_0lo': 1,\n",
       " 'w2_-lo': 1,\n",
       " 'w2_+back': 1,\n",
       " 'w2_0back': 1,\n",
       " 'w2_-back': 0,\n",
       " 'w2_+round': 1,\n",
       " 'w2_0round': 1,\n",
       " 'w2_-round': 0,\n",
       " 'w2_+velaric': 0,\n",
       " 'w2_0velaric': 1,\n",
       " 'w2_-velaric': 1,\n",
       " 'w2_+tense': 1,\n",
       " 'w2_0tense': 1,\n",
       " 'w2_-tense': 0,\n",
       " 'w2_+long': 0,\n",
       " 'w2_0long': 1,\n",
       " 'w2_-long': 1,\n",
       " 'w2_+hitone': 1,\n",
       " 'w2_0hitone': 1,\n",
       " 'w2_-hitone': 0,\n",
       " 'w2_+hireg': 1,\n",
       " 'w2_0hireg': 1,\n",
       " 'w2_-hireg': 0,\n",
       " 'w4_ton_g': False,\n",
       " 'w4_ton_v': False,\n",
       " 'w4_ton_j': False,\n",
       " 'w4_ton_0': True,\n",
       " 'w4_ton_b': False,\n",
       " 'w4_ton_s': False,\n",
       " 'w4_ton_m': False,\n",
       " 'w4_rhy_ua': False,\n",
       " 'w4_rhy_ai': False,\n",
       " 'w4_rhy_o': True,\n",
       " 'w4_rhy_e': False,\n",
       " 'w4_rhy_i': False,\n",
       " 'w4_rhy_u': False,\n",
       " 'w4_rhy_au': False,\n",
       " 'w4_rhy_aw': False,\n",
       " 'w4_rhy_ee': False,\n",
       " 'w4_rhy_w': False,\n",
       " 'w4_rhy_ia': False,\n",
       " 'w4_rhy_a': False,\n",
       " 'w4_rhy_oo': False,\n",
       " 'w4_rhy_aa': False,\n",
       " 'w4_ons_v': False,\n",
       " 'w4_ons_x': False,\n",
       " 'w4_ons_qh': False,\n",
       " 'w4_ons_k': False,\n",
       " 'w4_ons_t': False,\n",
       " 'w4_ons_txh': False,\n",
       " 'w4_ons_': False,\n",
       " 'w4_ons_nt': False,\n",
       " 'w4_ons_p': False,\n",
       " 'w4_ons_s': False,\n",
       " 'w4_ons_y': False,\n",
       " 'w4_ons_nq': False,\n",
       " 'w4_ons_n': True,\n",
       " 'w4_ons_tsh': False,\n",
       " 'w4_ons_th': False,\n",
       " 'w4_ons_ny': False,\n",
       " 'w4_ons_c': False,\n",
       " 'w4_ons_kh': False,\n",
       " 'w4_ons_l': False,\n",
       " 'w4_ons_ts': False,\n",
       " 'w4_ons_tx': False,\n",
       " 'w4_ons_h': False,\n",
       " 'w4_ons_m': False,\n",
       " 'w4_ons_r': False,\n",
       " 'w4_ons_nr': False,\n",
       " 'w4_ons_d': False,\n",
       " 'w4_ons_z': False,\n",
       " 'w4_ons_np': False,\n",
       " 'w4_ons_nrh': False,\n",
       " 'w4_ons_hl': False,\n",
       " 'w4_ons_ch': False,\n",
       " 'w4_ons_hm': False,\n",
       " 'w4_ons_ntx': False,\n",
       " 'w4_ons_nts': False,\n",
       " 'w4_ons_ntsh': False,\n",
       " 'w4_ons_hn': False,\n",
       " 'w4_ons_q': False,\n",
       " 'w4_ons_dh': False,\n",
       " 'w4_ons_pl': False,\n",
       " 'w4_ons_dl': False,\n",
       " 'w4_ons_ml': False,\n",
       " 'w4_ons_plh': False,\n",
       " 'w4_ons_nk': False,\n",
       " 'w4_ons_nc': False,\n",
       " 'w4_ons_npl': False,\n",
       " 'w4_ons_nch': False,\n",
       " 'w4_ons_ntxh': False,\n",
       " 'w4_ons_f': False,\n",
       " 'w4_ons_xy': False,\n",
       " 'w4_ons_ph': False,\n",
       " 'w4_ons_rh': False,\n",
       " 'w4_ons_nth': False,\n",
       " 'w4_ons_dlh': False,\n",
       " 'w4_ons_nph': False,\n",
       " 'w4_ons_ndl': False,\n",
       " 'w4_ons_nkh': False,\n",
       " 'w4_ons_nqh': False,\n",
       " 'w4_ons_hny': False,\n",
       " 'w4_+syl': 1,\n",
       " 'w4_0syl': 1,\n",
       " 'w4_-syl': 1,\n",
       " 'w4_+son': 2,\n",
       " 'w4_0son': 1,\n",
       " 'w4_-son': 0,\n",
       " 'w4_+cons': 1,\n",
       " 'w4_0cons': 1,\n",
       " 'w4_-cons': 1,\n",
       " 'w4_+cont': 1,\n",
       " 'w4_0cont': 1,\n",
       " 'w4_-cont': 1,\n",
       " 'w4_+delrel': 0,\n",
       " 'w4_0delrel': 1,\n",
       " 'w4_-delrel': 2,\n",
       " 'w4_+lat': 0,\n",
       " 'w4_0lat': 1,\n",
       " 'w4_-lat': 2,\n",
       " 'w4_+nas': 1,\n",
       " 'w4_0nas': 1,\n",
       " 'w4_-nas': 1,\n",
       " 'w4_+strid': 0,\n",
       " 'w4_0strid': 3,\n",
       " 'w4_-strid': 0,\n",
       " 'w4_+voi': 2,\n",
       " 'w4_0voi': 1,\n",
       " 'w4_-voi': 0,\n",
       " 'w4_+sg': 0,\n",
       " 'w4_0sg': 1,\n",
       " 'w4_-sg': 2,\n",
       " 'w4_+cg': 0,\n",
       " 'w4_0cg': 1,\n",
       " 'w4_-cg': 2,\n",
       " 'w4_+ant': 1,\n",
       " 'w4_0ant': 2,\n",
       " 'w4_-ant': 0,\n",
       " 'w4_+cor': 1,\n",
       " 'w4_0cor': 1,\n",
       " 'w4_-cor': 1,\n",
       " 'w4_+distr': 0,\n",
       " 'w4_0distr': 2,\n",
       " 'w4_-distr': 1,\n",
       " 'w4_+lab': 0,\n",
       " 'w4_0lab': 1,\n",
       " 'w4_-lab': 2,\n",
       " 'w4_+hi': 0,\n",
       " 'w4_0hi': 1,\n",
       " 'w4_-hi': 2,\n",
       " 'w4_+lo': 0,\n",
       " 'w4_0lo': 1,\n",
       " 'w4_-lo': 2,\n",
       " 'w4_+back': 1,\n",
       " 'w4_0back': 1,\n",
       " 'w4_-back': 1,\n",
       " 'w4_+round': 1,\n",
       " 'w4_0round': 1,\n",
       " 'w4_-round': 1,\n",
       " 'w4_+velaric': 0,\n",
       " 'w4_0velaric': 1,\n",
       " 'w4_-velaric': 2,\n",
       " 'w4_+tense': 0,\n",
       " 'w4_0tense': 2,\n",
       " 'w4_-tense': 1,\n",
       " 'w4_+long': 0,\n",
       " 'w4_0long': 1,\n",
       " 'w4_-long': 2,\n",
       " 'w4_+hitone': 0,\n",
       " 'w4_0hitone': 3,\n",
       " 'w4_-hitone': 0,\n",
       " 'w4_+hireg': 0,\n",
       " 'w4_0hireg': 3,\n",
       " 'w4_-hireg': 0}"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded_df.iloc[0].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word1    vuag\n",
       "word2      ub\n",
       "word3    vuag\n",
       "word4      no\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Decision Tree\n",
    "First try the entire dataset, without splitting into train and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(criterion='entropy', random_state=0).fit(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How accurate is this classifier?  -> 100%! This is overfitting, of course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try split on gini impurity index instead of entropy -- no change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_gini = DecisionTreeClassifier(criterion='gini', random_state=0).fit(X, y)\n",
    "clf_gini.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we do a train/test split  -> 94.0% - 96.2%, mean 95.4%\n",
    "With panphone features: 93.9% - 96.1%, mean 94.9%. Do feature extraction techniques to improve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DescribeResult(nobs=50, minmax=(0.9392838609237156, 0.9605604566683965), mean=0.9494862480539699, variance=2.168261790903827e-05, skewness=0.20993469006447252, kurtosis=-0.5410236734389335)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import describe\n",
    "\n",
    "accs = []\n",
    "for rnd in range(50):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=rnd)\n",
    "    clf_train = DecisionTreeClassifier(criterion='entropy', random_state=rnd).fit(X_train, y_train)\n",
    "    accs.append(clf_train.score(X_test, y_test))\n",
    "\n",
    "print(describe(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "Now that we can get 100% training accuracy with all 237 features, the natural thing to ask is how many features we can remove to still get close to 100% accuracy.\n",
    "DecisionTreeClassifier conveniently provides the `feature_importances_` attributes, which directly tells us that 103 of the features are completely useless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features that are completely useless\n",
      "286\n",
      "useless features: \n",
      "['w1_ton_g' 'w1_ton_m' 'w1_rhy_ua' 'w1_rhy_ai' 'w1_rhy_aw' 'w1_rhy_ee'\n",
      " 'w1_rhy_w' 'w1_rhy_ia' 'w1_ons_v' 'w1_ons_qh' 'w1_ons_t' 'w1_ons_txh'\n",
      " 'w1_ons_' 'w1_ons_nt' 'w1_ons_p' 'w1_ons_nq' 'w1_ons_n' 'w1_ons_tsh'\n",
      " 'w1_ons_th' 'w1_ons_ny' 'w1_ons_c' 'w1_ons_l' 'w1_ons_tx' 'w1_ons_h'\n",
      " 'w1_ons_m' 'w1_ons_nr' 'w1_ons_np' 'w1_ons_nrh' 'w1_ons_hl' 'w1_ons_ch'\n",
      " 'w1_ons_hm' 'w1_ons_ntx' 'w1_ons_nts' 'w1_ons_ntsh' 'w1_ons_hn'\n",
      " 'w1_ons_q' 'w1_ons_dh' 'w1_ons_pl' 'w1_ons_dl' 'w1_ons_ml' 'w1_ons_plh'\n",
      " 'w1_ons_nk' 'w1_ons_nc' 'w1_ons_npl' 'w1_ons_nch' 'w1_ons_ntxh'\n",
      " 'w1_ons_f' 'w1_ons_xy' 'w1_ons_ph' 'w1_ons_rh' 'w1_ons_nth' 'w1_ons_dlh'\n",
      " 'w1_ons_nph' 'w1_ons_ndl' 'w1_ons_nkh' 'w1_ons_nqh' 'w1_ons_hny'\n",
      " 'w1_+syl' 'w1_0syl' 'w1_0son' 'w1_-son' 'w1_-cons' 'w1_+cont' 'w1_0cont'\n",
      " 'w1_0delrel' 'w1_+lat' 'w1_0lat' 'w1_+strid' 'w1_-strid' 'w1_-voi'\n",
      " 'w1_+sg' 'w1_0sg' 'w1_-sg' 'w1_+cg' 'w1_0cg' 'w1_-cg' 'w1_+ant' 'w1_-ant'\n",
      " 'w1_+cor' 'w1_0cor' 'w1_-distr' 'w1_0lab' 'w1_-lab' 'w1_+hi' 'w1_+lo'\n",
      " 'w1_0lo' 'w1_-lo' 'w1_0back' 'w1_+velaric' 'w1_0velaric' 'w1_-velaric'\n",
      " 'w1_+tense' 'w1_+long' 'w1_0long' 'w1_-long' 'w1_0hitone' 'w1_+hireg'\n",
      " 'w2_ton_g' 'w2_ton_0' 'w2_rhy_ai' 'w2_rhy_o' 'w2_rhy_u' 'w2_rhy_au'\n",
      " 'w2_rhy_ee' 'w2_rhy_w' 'w2_rhy_ia' 'w2_rhy_oo' 'w2_ons_v' 'w2_ons_x'\n",
      " 'w2_ons_qh' 'w2_ons_txh' 'w2_ons_' 'w2_ons_nt' 'w2_ons_y' 'w2_ons_nq'\n",
      " 'w2_ons_n' 'w2_ons_th' 'w2_ons_ny' 'w2_ons_c' 'w2_ons_kh' 'w2_ons_l'\n",
      " 'w2_ons_ts' 'w2_ons_h' 'w2_ons_z' 'w2_ons_np' 'w2_ons_nrh' 'w2_ons_hl'\n",
      " 'w2_ons_hm' 'w2_ons_ntx' 'w2_ons_nts' 'w2_ons_ntsh' 'w2_ons_q'\n",
      " 'w2_ons_dh' 'w2_ons_pl' 'w2_ons_dl' 'w2_ons_ml' 'w2_ons_plh' 'w2_ons_nk'\n",
      " 'w2_ons_nch' 'w2_ons_ntxh' 'w2_ons_f' 'w2_ons_xy' 'w2_ons_ph' 'w2_ons_rh'\n",
      " 'w2_ons_nth' 'w2_ons_dlh' 'w2_ons_nph' 'w2_ons_ndl' 'w2_ons_nkh'\n",
      " 'w2_ons_nqh' 'w2_ons_hny' 'w2_+syl' 'w2_0syl' 'w2_0son' 'w2_+cons'\n",
      " 'w2_0cons' 'w2_-cons' 'w2_+cont' 'w2_-cont' 'w2_0delrel' 'w2_-delrel'\n",
      " 'w2_0lat' 'w2_-lat' 'w2_0nas' 'w2_0strid' 'w2_-strid' 'w2_+voi' 'w2_0voi'\n",
      " 'w2_0sg' 'w2_-sg' 'w2_+cg' 'w2_0cg' 'w2_-cor' 'w2_-distr' 'w2_0lab'\n",
      " 'w2_0hi' 'w2_0lo' 'w2_0back' 'w2_0round' 'w2_+velaric' 'w2_0velaric'\n",
      " 'w2_+tense' 'w2_+long' 'w2_-long' 'w2_0hitone' 'w2_-hitone' 'w2_0hireg'\n",
      " 'w4_ton_g' 'w4_ton_j' 'w4_ton_b' 'w4_rhy_e' 'w4_rhy_au' 'w4_rhy_aw'\n",
      " 'w4_rhy_ee' 'w4_rhy_w' 'w4_rhy_a' 'w4_rhy_oo' 'w4_ons_v' 'w4_ons_x'\n",
      " 'w4_ons_qh' 'w4_ons_txh' 'w4_ons_' 'w4_ons_p' 'w4_ons_s' 'w4_ons_y'\n",
      " 'w4_ons_nq' 'w4_ons_th' 'w4_ons_ny' 'w4_ons_kh' 'w4_ons_l' 'w4_ons_ts'\n",
      " 'w4_ons_h' 'w4_ons_m' 'w4_ons_d' 'w4_ons_z' 'w4_ons_np' 'w4_ons_nrh'\n",
      " 'w4_ons_hl' 'w4_ons_ch' 'w4_ons_hm' 'w4_ons_ntx' 'w4_ons_nts'\n",
      " 'w4_ons_ntsh' 'w4_ons_q' 'w4_ons_dh' 'w4_ons_pl' 'w4_ons_dl' 'w4_ons_ml'\n",
      " 'w4_ons_plh' 'w4_ons_nk' 'w4_ons_nc' 'w4_ons_npl' 'w4_ons_nch'\n",
      " 'w4_ons_ntxh' 'w4_ons_f' 'w4_ons_xy' 'w4_ons_ph' 'w4_ons_rh' 'w4_ons_nth'\n",
      " 'w4_ons_dlh' 'w4_ons_nph' 'w4_ons_ndl' 'w4_ons_nkh' 'w4_ons_nqh'\n",
      " 'w4_ons_hny' 'w4_+syl' 'w4_0syl' 'w4_0son' 'w4_+cons' 'w4_0cons'\n",
      " 'w4_-cons' 'w4_0cont' 'w4_0delrel' 'w4_0lat' 'w4_-lat' 'w4_0nas'\n",
      " 'w4_+strid' 'w4_-strid' 'w4_+voi' 'w4_0voi' 'w4_-voi' 'w4_0sg' 'w4_+cg'\n",
      " 'w4_0cg' 'w4_-cg' 'w4_+cor' 'w4_0cor' 'w4_+distr' 'w4_0lab' 'w4_-lab'\n",
      " 'w4_0hi' 'w4_+lo' 'w4_0lo' 'w4_0back' 'w4_0round' 'w4_+velaric'\n",
      " 'w4_0velaric' 'w4_-velaric' 'w4_-tense' 'w4_+long' 'w4_0long' 'w4_-long'\n",
      " 'w4_+hitone' 'w4_-hitone' 'w4_0hireg' 'w4_-hireg']\n"
     ]
    }
   ],
   "source": [
    "print(\"number of features that are completely useless\")\n",
    "print((clf.feature_importances_ == 0).sum())\n",
    "print(\"useless features: \")\n",
    "print(expanded_df.columns.to_numpy()[1:][clf.feature_importances_ == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100, 1.000, 0.952\n",
      "90, 1.000, 0.952\n",
      "80, 1.000, 0.952\n",
      "70, 0.999, 0.953\n",
      "60, 0.999, 0.953\n",
      "50, 0.998, 0.953\n",
      "40, 0.990, 0.958\n",
      "35, 0.990, 0.957\n",
      "30, 0.987, 0.957\n",
      "25, 0.984, 0.956\n",
      "20, 0.979, 0.954\n",
      "15, 0.952, 0.938\n",
      "10, 0.907, 0.903\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "\n",
    "clf_best = None\n",
    "best_accs = 0\n",
    "for t in (100, 90, 80, 70, 60, 50, 40, 35, 30, 25, 20, 15, 10):\n",
    "    model = SelectFromModel(clf, prefit=True, threshold=-np.inf, max_features=t)\n",
    "    X_new = model.transform(X)\n",
    "#     print(f\"new feature set has {X_new.shape[1]} features\")\n",
    "    print(X_new.shape[1], end=', ')\n",
    "\n",
    "\n",
    "    clf_new = DecisionTreeClassifier(criterion='entropy', random_state=0).fit(X_new, y)\n",
    "#     print(f\"full training accuracy is {clf_new.score(X_new, y):.3f}\")\n",
    "    print(f\"{clf_new.score(X_new, y):.3f}\", end=', ')\n",
    "\n",
    "    accs = []\n",
    "    for rnd in range(10):\n",
    "        X_new_train, X_new_test, y_train, y_test = train_test_split(X_new, y, test_size=0.3, random_state=rnd)\n",
    "        clf_train = DecisionTreeClassifier(criterion='entropy', random_state=rnd).fit(X_new_train, y_train)\n",
    "        accs.append(clf_train.score(X_new_test, y_test))\n",
    "#     print(f\"average test accuracy is {np.mean(accs):.3f}\")\n",
    "#     print(\"=\"*40)\n",
    "    mean_accs = np.mean(accs)\n",
    "    if mean_accs > best_accs:\n",
    "        best_accs = mean_accs\n",
    "        clf_best = clf_new\n",
    "    print(f\"{mean_accs:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DecisionTreeClassifier'"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.__class__.__name__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot in /home/cuichenx/anaconda3/envs/py38/lib/python3.8/site-packages (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in /home/cuichenx/anaconda3/envs/py38/lib/python3.8/site-packages (from pydot) (2.4.7)\n",
      "Requirement already satisfied: graphviz in /home/cuichenx/anaconda3/envs/py38/lib/python3.8/site-packages (0.17)\n"
     ]
    }
   ],
   "source": [
    "!pip install pydot\n",
    "!pip install graphviz\n",
    "# note: also need to install graphviz on your system: https://www.graphviz.org/\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_best.n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = expanded_df.columns.to_list()[1:]\n",
    "class_names = ['FAKE', 'ATT']\n",
    "\n",
    "d = 15 # max depth. Use None if unlimited\n",
    "\n",
    "fname = f'../out/tree_{use_features}_{d or \"\"}.dot'\n",
    "export_graphviz(clf, \n",
    "                out_file=fname, \n",
    "                impurity=False, \n",
    "                feature_names=feature_names,\n",
    "                class_names=class_names,\n",
    "                max_depth=d)\n",
    "\n",
    "f = pydot.graph_from_dot_file(fname)[0].to_string()\n",
    "# print(len(f), '\\n', f[:1000])\n",
    "# f = re.sub(r'(\\\\nvalue = \\[.*?\\])', '', f)  # get rid of nvalue = [anychar, lazy]\n",
    "# f = f.replace(' <= 0.5', '?')  # change decision to a question\n",
    "# f = f.replace('headlabel=\"True\"', 'headlabel=\"No\"')  # change to yes no rather than <=0.5 true false\n",
    "# f = f.replace('headlabel=\"False\"', 'headlabel=\"Yes\"')\n",
    "# f = f.replace(R'samples = 1\\nclass = ', R'***\\n')  # change text of leaf node\n",
    "# print(\"============================\")\n",
    "# print(len(f), '\\n', f[:1000])\n",
    "\n",
    "with open(fname, 'w') as file:\n",
    "    file.write(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"../out/tree_ton_rhy_ons_panphon_15.dot.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graphviz\n",
    "from IPython.display import Image\n",
    "savepath = graphviz.render('dot', 'png', fname)\n",
    "Image(url=savepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>word3</th>\n",
       "      <th>word4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tuav</td>\n",
       "      <td>kwv</td>\n",
       "      <td>tuav</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ua</td>\n",
       "      <td>kwv</td>\n",
       "      <td>ua</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>nws</td>\n",
       "      <td>kwv</td>\n",
       "      <td>nws</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>lawv</td>\n",
       "      <td>kwv</td>\n",
       "      <td>lawv</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>yog</td>\n",
       "      <td>kwv</td>\n",
       "      <td>yog</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>rau</td>\n",
       "      <td>kwv</td>\n",
       "      <td>rau</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>cov</td>\n",
       "      <td>kwv</td>\n",
       "      <td>cov</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>tej</td>\n",
       "      <td>kwv</td>\n",
       "      <td>tej</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>nyias</td>\n",
       "      <td>kwv</td>\n",
       "      <td>nyias</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>tsham</td>\n",
       "      <td>kwv</td>\n",
       "      <td>tsham</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>muaj</td>\n",
       "      <td>kwv</td>\n",
       "      <td>muaj</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>tus</td>\n",
       "      <td>kwv</td>\n",
       "      <td>tus</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>tau</td>\n",
       "      <td>kwv</td>\n",
       "      <td>tau</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>koj</td>\n",
       "      <td>kwv</td>\n",
       "      <td>koj</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>kuv</td>\n",
       "      <td>kwv</td>\n",
       "      <td>kuv</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>kev</td>\n",
       "      <td>kwv</td>\n",
       "      <td>kev</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>ntshaw</td>\n",
       "      <td>kwv</td>\n",
       "      <td>ntshaw</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>luag</td>\n",
       "      <td>kwv</td>\n",
       "      <td>luag</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>nej</td>\n",
       "      <td>kwv</td>\n",
       "      <td>nej</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>pab</td>\n",
       "      <td>kwv</td>\n",
       "      <td>pab</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292</th>\n",
       "      <td>kho</td>\n",
       "      <td>kwv</td>\n",
       "      <td>kho</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1408</th>\n",
       "      <td>yus</td>\n",
       "      <td>kwv</td>\n",
       "      <td>yus</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>lawb</td>\n",
       "      <td>kwv</td>\n",
       "      <td>lawb</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>xav</td>\n",
       "      <td>kwv</td>\n",
       "      <td>xav</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>taug</td>\n",
       "      <td>kwv</td>\n",
       "      <td>taug</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1624</th>\n",
       "      <td>tag</td>\n",
       "      <td>kwv</td>\n",
       "      <td>tag</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626</th>\n",
       "      <td>hu</td>\n",
       "      <td>kwv</td>\n",
       "      <td>hu</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>lawm</td>\n",
       "      <td>kwv</td>\n",
       "      <td>lawm</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1647</th>\n",
       "      <td>hais</td>\n",
       "      <td>kwv</td>\n",
       "      <td>hais</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1828</th>\n",
       "      <td>tshuav</td>\n",
       "      <td>kwv</td>\n",
       "      <td>tshuav</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1833</th>\n",
       "      <td>zoo</td>\n",
       "      <td>kwv</td>\n",
       "      <td>zoo</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1924</th>\n",
       "      <td>raws</td>\n",
       "      <td>kwv</td>\n",
       "      <td>raws</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>nyuag</td>\n",
       "      <td>kwv</td>\n",
       "      <td>nyuag</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>me</td>\n",
       "      <td>kwv</td>\n",
       "      <td>me</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>ntsuag</td>\n",
       "      <td>kwv</td>\n",
       "      <td>ntsuag</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047</th>\n",
       "      <td>tso</td>\n",
       "      <td>kwv</td>\n",
       "      <td>tso</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2081</th>\n",
       "      <td>tug</td>\n",
       "      <td>kwv</td>\n",
       "      <td>tug</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2092</th>\n",
       "      <td>vam</td>\n",
       "      <td>kwv</td>\n",
       "      <td>vam</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2163</th>\n",
       "      <td>tos</td>\n",
       "      <td>kwv</td>\n",
       "      <td>tos</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2186</th>\n",
       "      <td>zeem</td>\n",
       "      <td>kwv</td>\n",
       "      <td>zeem</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2201</th>\n",
       "      <td>hlub</td>\n",
       "      <td>kwv</td>\n",
       "      <td>hlub</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2216</th>\n",
       "      <td>tawg</td>\n",
       "      <td>kwv</td>\n",
       "      <td>tawg</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2257</th>\n",
       "      <td>peb</td>\n",
       "      <td>kwv</td>\n",
       "      <td>peb</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2370</th>\n",
       "      <td>saib</td>\n",
       "      <td>kwv</td>\n",
       "      <td>saib</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2388</th>\n",
       "      <td>tu</td>\n",
       "      <td>kwv</td>\n",
       "      <td>tu</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2424</th>\n",
       "      <td>xaav</td>\n",
       "      <td>kwv</td>\n",
       "      <td>xaav</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2560</th>\n",
       "      <td>ncu</td>\n",
       "      <td>kwv</td>\n",
       "      <td>ncu</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2663</th>\n",
       "      <td>yuav</td>\n",
       "      <td>kwv</td>\n",
       "      <td>yuav</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2687</th>\n",
       "      <td>lis</td>\n",
       "      <td>kwv</td>\n",
       "      <td>lis</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2744</th>\n",
       "      <td>sau</td>\n",
       "      <td>kwv</td>\n",
       "      <td>sau</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2748</th>\n",
       "      <td>nwg</td>\n",
       "      <td>kwv</td>\n",
       "      <td>nwg</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2759</th>\n",
       "      <td>txheeb</td>\n",
       "      <td>kwv</td>\n",
       "      <td>txheeb</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2763</th>\n",
       "      <td>nrog</td>\n",
       "      <td>kwv</td>\n",
       "      <td>nrog</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2837</th>\n",
       "      <td>nug</td>\n",
       "      <td>kwv</td>\n",
       "      <td>nug</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2886</th>\n",
       "      <td>nus</td>\n",
       "      <td>kwv</td>\n",
       "      <td>nus</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2895</th>\n",
       "      <td>txav</td>\n",
       "      <td>kwv</td>\n",
       "      <td>txav</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2912</th>\n",
       "      <td>pe</td>\n",
       "      <td>kwv</td>\n",
       "      <td>pe</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2922</th>\n",
       "      <td>paub</td>\n",
       "      <td>kwv</td>\n",
       "      <td>paub</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2928</th>\n",
       "      <td>qeej</td>\n",
       "      <td>kwv</td>\n",
       "      <td>qeej</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2938</th>\n",
       "      <td>li</td>\n",
       "      <td>kwv</td>\n",
       "      <td>li</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2964</th>\n",
       "      <td>tsawg</td>\n",
       "      <td>kwv</td>\n",
       "      <td>tsawg</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3122</th>\n",
       "      <td>nkawd</td>\n",
       "      <td>kwv</td>\n",
       "      <td>nkawd</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3123</th>\n",
       "      <td>yaum</td>\n",
       "      <td>kwv</td>\n",
       "      <td>yaum</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3145</th>\n",
       "      <td>has</td>\n",
       "      <td>kwv</td>\n",
       "      <td>has</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3153</th>\n",
       "      <td>nrhiav</td>\n",
       "      <td>kwv</td>\n",
       "      <td>nrhiav</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3188</th>\n",
       "      <td>thum</td>\n",
       "      <td>kwv</td>\n",
       "      <td>thum</td>\n",
       "      <td>tij</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word1 word2   word3 word4\n",
       "18      tuav   kwv    tuav   tij\n",
       "24        ua   kwv      ua   tij\n",
       "32       nws   kwv     nws   tij\n",
       "37      lawv   kwv    lawv   tij\n",
       "329      yog   kwv     yog   tij\n",
       "417      rau   kwv     rau   tij\n",
       "461      cov   kwv     cov   tij\n",
       "503      tej   kwv     tej   tij\n",
       "567    nyias   kwv   nyias   tij\n",
       "571    tsham   kwv   tsham   tij\n",
       "678     muaj   kwv    muaj   tij\n",
       "732      tus   kwv     tus   tij\n",
       "790      tau   kwv     tau   tij\n",
       "811      koj   kwv     koj   tij\n",
       "812      kuv   kwv     kuv   tij\n",
       "996      kev   kwv     kev   tij\n",
       "1215  ntshaw   kwv  ntshaw   tij\n",
       "1220    luag   kwv    luag   tij\n",
       "1268     nej   kwv     nej   tij\n",
       "1271     pab   kwv     pab   tij\n",
       "1292     kho   kwv     kho   tij\n",
       "1408     yus   kwv     yus   tij\n",
       "1461    lawb   kwv    lawb   tij\n",
       "1498     xav   kwv     xav   tij\n",
       "1593    taug   kwv    taug   tij\n",
       "1624     tag   kwv     tag   tij\n",
       "1626      hu   kwv      hu   tij\n",
       "1635    lawm   kwv    lawm   tij\n",
       "1647    hais   kwv    hais   tij\n",
       "1828  tshuav   kwv  tshuav   tij\n",
       "1833     zoo   kwv     zoo   tij\n",
       "1924    raws   kwv    raws   tij\n",
       "1977   nyuag   kwv   nyuag   tij\n",
       "1996      me   kwv      me   tij\n",
       "1999  ntsuag   kwv  ntsuag   tij\n",
       "2047     tso   kwv     tso   tij\n",
       "2081     tug   kwv     tug   tij\n",
       "2092     vam   kwv     vam   tij\n",
       "2163     tos   kwv     tos   tij\n",
       "2186    zeem   kwv    zeem   tij\n",
       "2201    hlub   kwv    hlub   tij\n",
       "2216    tawg   kwv    tawg   tij\n",
       "2257     peb   kwv     peb   tij\n",
       "2370    saib   kwv    saib   tij\n",
       "2388      tu   kwv      tu   tij\n",
       "2424    xaav   kwv    xaav   tij\n",
       "2560     ncu   kwv     ncu   tij\n",
       "2663    yuav   kwv    yuav   tij\n",
       "2687     lis   kwv     lis   tij\n",
       "2744     sau   kwv     sau   tij\n",
       "2748     nwg   kwv     nwg   tij\n",
       "2759  txheeb   kwv  txheeb   tij\n",
       "2763    nrog   kwv    nrog   tij\n",
       "2837     nug   kwv     nug   tij\n",
       "2886     nus   kwv     nus   tij\n",
       "2895    txav   kwv    txav   tij\n",
       "2912      pe   kwv      pe   tij\n",
       "2922    paub   kwv    paub   tij\n",
       "2928    qeej   kwv    qeej   tij\n",
       "2938      li   kwv      li   tij\n",
       "2964   tsawg   kwv   tsawg   tij\n",
       "3122   nkawd   kwv   nkawd   tij\n",
       "3123    yaum   kwv    yaum   tij\n",
       "3145     has   kwv     has   tij\n",
       "3153  nrhiav   kwv  nrhiav   tij\n",
       "3188    thum   kwv    thum   tij"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 100)\n",
    "df[(df.word4.str.endswith('j')) & (df.word2.str.startswith('k')) & (df.word4.str.contains('i'))]\n",
    "# pd.set_option('display.max_rows', 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py38] *",
   "language": "python",
   "name": "conda-env-py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
